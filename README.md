<!-- Language Switcher -->
<div align="right">
	[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)
</div>

<a name="english"></a>
# LLM training demo {#english}

A minimal, practical repo for training your own GPT-style LLM from scratch, including pretraining, SFT and RLHF/DPO.

---

## ğŸš€ Quick Start

### 1. Installation

```bash
conda create -n llm python=3.10 -y
conda activate llm
pip install -r requirements.txt
```

### 2. Download Data

```bash
python src/data/download_base.py --dataset wikitext2
python src/data/download_sft.py --dataset alpaca
python src/data/download_preference.py --dataset ultrafeedback
```

### 3. Train Tokenizer

```bash
python src/data/tokenizer.py --action train
```

### 4. Pretrain GPT Model

```bash
python src/training/pretrain.py --model_size small --batch_size 8 --num_epochs 10
```

### 5. SFT Instruction Fine-tuning

```bash
python src/training/sft.py --pretrained_path pretrain_run --prompt_template alpaca --batch_size 4 --num_epochs 3
```

### 6. DPO Preference Training

```bash
python src/training/dpo.py --sft_model_path sft_run --batch_size 4 --num_epochs 1
```

### 7. RLHF Training (Optional)

```bash
python src/training/rlhf.py reward --sft_model_path sft_run
python src/training/rlhf.py ppo --sft_model_path sft_run --reward_model_path reward_model_run
```

---

<a name="ä¸­æ–‡"></a>
# LLM training demo {#ä¸­æ–‡}

æœ¬é¡¹ç›®ä¸ºä»é›¶è®­ç»ƒGPTé£æ ¼å¤§æ¨¡å‹çš„æç®€å®ç”¨ä»£ç ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒã€SFTã€RLHF/DPOç­‰æµç¨‹ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
conda create -n llm python=3.10 -y
conda activate llm
pip install -r requirements.txt
```

### 2. ä¸‹è½½æ•°æ®

```bash
python src/data/download_base.py --dataset wikitext2
python src/data/download_sft.py --dataset alpaca
python src/data/download_preference.py --dataset ultrafeedback
```

### 3. è®­ç»ƒåˆ†è¯å™¨

```bash
python src/data/tokenizer.py --action train
```

### 4. é¢„è®­ç»ƒGPTæ¨¡å‹

```bash
python src/training/pretrain.py --model_size small --batch_size 8 --num_epochs 10
```

### 5. SFTæŒ‡ä»¤å¾®è°ƒ

```bash
python src/training/sft.py --pretrained_path pretrain_run --prompt_template alpaca --batch_size 4 --num_epochs 3
```

### 6. DPOåå¥½è®­ç»ƒ

```bash
python src/training/dpo.py --sft_model_path sft_run --batch_size 4 --num_epochs 1
```

### 7. RLHFè®­ç»ƒï¼ˆå¯é€‰ï¼‰

```bash
python src/training/rlhf.py reward --sft_model_path sft_run
python src/training/rlhf.py ppo --sft_model_path sft_run --reward_model_path reward_model_run
```

---

